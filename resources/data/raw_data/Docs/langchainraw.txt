Good morning, everyone. How is it going today? Welcome to this amazing tutorial in which I'm going to show you exactly how to build this application that you are seeing in front of you. OK, let me show you real quick. How it works? So it's it has a graphical user interface of course, completely coded in Python And then if you write, if you drop right here a PDF and drop it in the constitution of the United States, it shows this text input in which you can ask a question. About your PDF. OK, so if I ask has who has the power to veto legislation passed by Congress and I click enter, it will answer me based on my PDF. But if I ask a question that has nothing to do with my PDF. So for example, what is the distance? Between the earth and the moon, for example, and I click enter and you will see that. It has no idea because it's not information that you can find inside my PDF. OK, I will show you how to parse this PDF, how to divide it into different chunks and also as a bonus I'm going to show you in the end how to track exactly how much money you're spending per per request. OK. We're going to be building this with lynching and I'm going to be explaining to you a little bit about how lynching works and the amazing things that you can do with it. OK, subscribe if you want more videos like this going to be publishing many more videos about lynching and yeah, let's get right into it. All right. So the first thing that we're going to be doing is we're going to set up our environment, OK. So as you can see right here I have created my end file which is the place where we're going to be storing our secret keys. In this case it is my open AI API key. And my dot end example which is the one that is going to be tracked on git, because this one right here will actually have our secrets, which is the actual API. Please be careful. You want you're going to want to name your API environment key exactly like this. If you're going to be working with open AI. Because since we're going to be working with Lang Chain it, it requires your environment variable for the open AI. An API to be exactly this name, otherwise it will not recognise it. OK, so it's got to be open. Lower Dash API, low dash key all. Right. There you go. Then we're going to have a git ignore right here. And for that, I'm just going to come right here and I'm going to copy a very standard git ignore so that I know that I am well covered, and then I have my app dot PY. Which is the place where we're going to start building our application? OK. All right. So First things first, we're going to want to install our dependencies, the dependencies that we're going to need in this case are line chain. First of all, π PDF two to read our our PDF files. We're going to need Python dot ENV to enable our environment variables and we're going to need. Streamlet to create our graphical user interface OK. This was super fast to me because I already have them installed, but for you it might take a little bit longer. Also, don't hesitate to install additional dependencies that you might need that I may have forgotten, because while you're when you will be running your application, you might be running into problems like oh, this dependency is not installed. Or this other dependency is not installed. Usually you all you have to do is just read the error message and it will tell you which dependency you're missing, right? So there you go. And then just to just to start off with this, I'm just going to. Just going to write this very basic test right here that this line I usually just added every single time I start a Python programme which basically just tests that my application is being run directly and not being imported. And then only then will it actually execute. The main content of the application. So there we go. Let's see how this looks. If I run it, I see hello world. Alright, so there we go. My project is set up my API key. All I have to do is come right here to my platform.openai.com. I have to create a new secret key. I'm going to call it PDF chat tutorial. I'm just going to copy it from here. I'm going to paste it right. Here save and then if I come right here and I say from 10. Import load the 10:00 and then I do. I'm going to have to do load dot end like this and then I'm going to print. I'm going to print out also. I'm also going to need OS. Import OS. I'm going. I'm going to be able to access my API key. OK, this is just to show you how how you will be able to access your API key and this is what launching is going to be doing in the behind the scenes. So if I. Do OS dot. Get environment get in. And I asked for open AI. Oops. Open AI. API key. Sorry this is not supposed to go inside of here. This is supposed to go inside. Of print. There you go. Now if I save this and I run it again, you can see that my API key is being recognised and this file is not being tracked on Git, so that's very important to keep your secrets secret. Right. So there you go. Now that our project is set up, we can start building our application to start parsing your PDF files, right? So let's do that now. All right, so now it is time to actually start creating our graphical user interface. I'm just going to disable. Get help copilot right here. Just so that you can code along. And there you go. In order to create our graphical user interface, we're going to be using Streamlet, so I'm going to import streamlet that I already installed, and I'm going to download it as imported as St. There you go. And now we can actually just start. Setting the post configuration, I'm going to save the page title. The page title is going to be. Ask your PDF. There we go. Now let's set header. To ask your PDF, I'm just going to add a little emoji like this. There you go and then below this I'm just going to create my input where I'm going to be able to upload my PDF. OK, so I'm going to do. SD file uploader. And then I'm going. To say. Upload your PDF right here. I'm going to say that the type is. PDF like that. All right. Now in order to run this, I'm going to have to do a let's just one second. I'm going to have to. Do string lit. Going to run and I'm going to have to target this file right here where my application lives. Now if I click on enter. It's going to open my new application and. It already looks. Pretty much like this. So that's pretty good. Although so far it doesn't do anything if I upload my file right here, it just shows that it's been uploaded. But it doesn't do anything else, right? So let's just add a little bit of functionality right here, just very quick before that in case you don't know what is going on. Stream lit is a very. Extremely, this is a very, very fast and convenient way of building these kind of applications with Python. As you can see, I just added three lines of codes right here, 3 lines of code, and it already outputs this with a with a very nice title. Nice. With nice tiles and all. So there you go. I mean, if you want to explore other kinds of components, for example, right here, just use a file upload component, but you can see that they have many many components for you to use, so don't hesitate to take a look into that. All right, so now it is time to actually start adding some logic to our application and to add our PDF reader and parser right. So let's do that now. Right. So now what we're going to want to do is to actually take the PDF file and read it, because so far we only have the file that we have right here, but we don't know what the text inside it is. And in order to read it, we're going to have to use one library that we imported a moment ago, which is. PDF two, right, so I'm going to do from π PDF 2 and I'm going to import this class that is PDF and PDF reader like this. And this is the one that is going to allow me to take the text out of my. PDF all right. So now what I'm going to want to do is I'm going to 1st test that my PDF file exists. So if my PDF is not null, if it's not none. What I'm going to do is I am going to create a new a new PDF reader that is going to do this. I'm going to PDF reader like this and I'm just going to use the new class that I imported. I'm going to initialise it with my PDF file that. That the user uploaded OK, so just to be clear right here we are uploading. Well, right here we are going to extract the text of the file. OK, once we have the PDF reader, we can actually loop through the pages of the PDF reader. OK, because the the the reader does not by default allow you to take all of the text. It allows you to take the pages. And then the text out of each page. So first we're going to take, we're going to look through the pages and then extract the text from there. In order to do that, we're going to initialise an empty string variable, and then we're going to say that for each page in our PDF reader dot pages. This is going to create a list with all the page elements inside of my PDF reader. I'm going to say that the text the text is going to concatenate with. Page dot extract text which is the method that is going to take the the string text out of our out of our page and then with this text what we're going to do is we're just going to write it in our. In our application, just to show you what is going on so far, OK, if I'm not mistaken and if I rerun this thing. And if I upload the Constitution again, I should see the Constitution text right here. There you go. Seems to be working alright. OK, so there you go. Now what we're going to want to do afterwards is to figure out a way on how to look for information inside of this text. OK, so let's let's get into that. All right, so we. Have a problem. Now remember that we said that we wanted. Our language model to answer questions depending on the information that we have in the PDF. Right. I mean normally in something like ChatGPT which works with the GPT 3.5 model. Normally in ChatGPT you would just give it the text and then just ask the question underneath, right? So you will send, you will send it something like this paragraph and then you say what is the? I don't know. Just write, ask something about that paragraph, right? And the problem right here is that this is just too much text. We cannot feed this enormous quantity of text to a language model and expect it to understand it in one go. So what we're going to want to do is we're going to split the text into. Similar sized chunks and then look inside those chunks to see which chunks contain the information. Corresponding to our question and then feed those chunks to the language model. OK, I found this article in in in the Internet from this guy or girl called Penney's might hack and it's got this very nice. Diagram which I upscaled for you right here. So shout out to to him and it's a very nice diagram and it makes it super easy to understand what is going on right here. So basically we have, I mean he calls it the book, but in our case it's just. PDF and we're going to extract the content and then I mean this is the complete process of what is going on in the back of our application. OK, so first we take our PDF, we extract the content just like we did. This is the content that we have right here. And then we're going to split it into two. Chunks all right. So we're going to take this text and we're going to split it. So this is going to be the first chunk, then this is going to be the second chunk this. Is going. To be the third chunk, etc. And then each of those chunks we're going to convert them into embeddings, which are basically just vector representations of your text. What does that mean? Basically you can see it as a list of numbers that contains the meaning of your text, and I mean that's the most basic explanation for it, but. It's just a number representation of the meaning of your text. And this way this vectors are going to be stored in your knowledge base. And then when the user comes here and asks a question. The question is going to be embedded using the same embedding technique that we used for the text chunks, and that is going to allow us to perform a semantic search which is going to find the vectors right here that are similar to our vector of our question. And this will allow us to find the chunks. That actually contain the information that we need and that is those chunks that we're going to feed to our language model. And it is like that that we're actually going to get an answer. In the end. Right, so this is basically how the entire application is going to. It's going to work. In the back, while we just ask a question right here, so right now what we're going to do is going to divide this text into into chunks, alright. And we're going to do that using line chain. All right there. We go. So now what? We're going to want to do is we're going to divide our text into chunks and we're going to be using this library from this. I'm sorry this function from link chain, right, so. First of all, I'm going to do from Lang Chain thought text splitter. I'm going to import. Character text splitter, right? And it is this one right? Here that remember all. Still inside of my if PDF. Actually, I'm going to modularize it in a moment, but right here I'm going to say extract. I mean, uh, split, split. Into chunks. There you go. And now let's actually split it into chunks. And we're going. To first have to create our text. Later, like this and we're going to use our character text splitter class that we imported before. Sorry I mentioned that it was a function before, but it's actually a. Class and this object takes different. This object has different. Properties. The first one is going to be the separator, which is the. The separator that's going to define a new line basically. So I mean in our PDF a single line break is just going to be a new line and then we have the chunk size. Chunk size like this and this one is going to be 1000 characters. OK, this basically means that off all of this text, we're going to take the 1st 1000 characters and then the 2nd 1000 characters and then the third thousand characters, et cetera. OK. And then we have another thing called chunk overlap, OK. And this one I'm going to set it to 200. What does the chunk over like mean overlap mean? Well, it basically means that if you come here and your chunk size is 1000 and your thousand and somewhere like here in in like in the middle of a sentence. Then the next chunk is going to start 200. I mean like every time the next chunk is going to start 200 characters before this one. So this is the first chunk and the 2nd chunk is going to be something like this and the third chunk is going to be something like this so. It basically just allows you. To get more context into each chunk alright and not split ideas in the middle. And then the length function button length, the length. Function that we're going to use to measure the length of our chunks is going to be python's basic function length.
There you.
Go and then once we have our text later initialised, we can just run it to create our chunks like this. Text splitter and we're going to say that we're going to split text and we're just going to pass in the whole corpus of text that we extracted from our PDF, which is currently stored in our text variable right here. And now what I'm going to do is I'm going to St right the chunks so that you can see what this looks like, right? So I'm saving coming back here, going to going to refresh the page and once again I'm going to upload my constitution. And there you go. Here we have that the first term, I mean here as you can see, we have an array and you can see that the first chunk goes all the way to qualify. I don't know. But then the second one starts at Section 2. As you can see. Section 2. So I mean it basically just makes it easier to to have context. I mean this is this is the overlap in work, right? So these are the 200 characters that we said that we wanted the overlap full and these are the chunks that we're going to use to create our embeddings and to look for the actual information. Later, right. So there you go. Now that we have our chunks, let's just convert them into embeddings. All right. There we go. So now, as you can see, we have our chunks and we're going to convert them into embeddings. So basically we are right here. We already had our text. We already extracted our content, we divided it into different chunks and now what we want to do is we want to convert. Each of these chunks into embeddings. And turn and take this. All of these embeddings and make them all of our knowledge base, which is going to be a document object on which we're going to be able to run a similarity. I mean, a semantic search to find the chunks that are actually relevant to our question. OK. So let me show you how to do that. The first thing that we're going to want to do is we're going to want to import from land chain. Dot embeddings dot open AI we're going to import the open AI embeddings like that. OK. I mean you are importing them from land chain but they come from opening eye. This is just a wrapper. OK. So right here, what we're going to do is we're going to say that our embeddings is going to be equal to our open AI embeddings like that is going to add a comment right here. Create embedded things. There you go. And now with these embeddings, we can actually create our object that is going to be able on which we're going to be able. To search right. And in order to search on this document, we're going to use this AI. As face, which is the Facebook AI similarity search library, it's basically just a library developed by Facebook that allows you to perform this this similarity search this semantic search. In the knowledge base. OK, so we're going to have to import that one too. And in order to import it, we're going to say that also from line chain and from vector stores, we're going to import files there. You. Go and now. We can actually create our document on which we will be able to perform the semantic search. So I'm going to say that my document is going to be vice. That from texts because we're going to create it from chunks of texts, and then we're just going to say the first argument we're going to pass is the chunks that we have here. Right. And the second one is the embeddings that we're going to use, which is the embeddings from open AI. OK. So yeah, this is looking pretty good. Let me just change this name right here to. Knowledge base because this is actually what we have finished creating. OK, we successfully created the knowledge base out of our PDF file. Let me just show you here in the in the diagram that we showed before where we are exactly at this time. So we already imported our PDF file, we extracted the text from that PDF file and then we split it into several chunks to make it easier for our language model to. Work with them. Then each one of those chunks we used open UI embeddings to convert them. In two vector representation of those same chunks and we used Facebook. 'S semantic search AI to build our knowledge base on which we're going to be able to look for the chunks. Using the embeddings that are related to the users question. OK, so whenever a user asks a question, we're going to come to this knowledge base that we created before and we're going to run a semantic search to find the chunks that that are closer to that question. So that we can send into the language model and use that to answer our questions. OK, so. This is where. We are so. Far and this means that we have successfully finished all of this part, which is the. All of this. Part Now what we're going to do is we're going to start coding this part. The user interaction part. OK, so let's get right. Into it. Right, right. So what we're going to do now is basically add an input element right here, OK, and this is where the user is going to be able to ask. And their questions, OK, so the idea is that I'm going to upload a PDF here and then once that PDF is properly. Uploaded extracted the text, split into chunks and created the knowledge base from the embeddings. We're going to show a an input, a text input labelled ask a question about your. PDF. There you go and we're going to store this value from this input in a variable called user question. Like this. Now if I save it. And I refresh this and I. Upload my file again. You can see that it's running. I mean that means that it's splitting and embedding and all. And now I have my question right. Here. Now what I'm going to do now, I'm going to say that I'm going to show user input, there we go. And now if we have, if we have user question. What we're going to do with that user question is we're going to look in our knowledge base to see if we find any chunks that could have important information about that question. OK. So in order to do that, we're going to. Create a new a new element called Docs which is going to be the documents in which we're going to. I mean the documents that contain important information and the the chunks that contain information about our our question and we're going to say that we're going to search in our. Knowledge base. We're going to go for similarity search, which is a method from the phase class from the Facebook similar to search AI and then we're going to look for users question. There you go. And now let's just write. The docs to see what we found. OK, so now if I save this and I refresh this right here. And I drag a constitution again. There you go. Now you can see that it's running, embedding, etc. Now if I come here and I re ask the question. And I press enter, it's going to perform a similarity search and it's going to find the chunks that are most relevant to this question. So according to the Facebook, so AI in our knowledge base, these are the four chunks that are. More likely to contain the information that we need to respond to this question. OK. And now it. Is this talks? That we are going to use to actually answer the question. With our with. Our language model. OK, so let's do that now. Perfect. So as we mentioned before, what we're going to do now is we're going to use these documents right here, which are the chunks that we just retrieved with the similarity search and this question right here to actually answer a question based on those chunks of text, right. And length chain actually comes with a very convenient chain that is already built for that, OK. And that one is actually this one right here that they have. Question answering for docs and this is the chain that we're looking at. It's called load QA chain. It takes a language model as parameter. We're going to be using open AI, but I mean you can use any other language model if you want. You can. Use it an open source language model. It's I mean this one takes pretty much any language model from the wrappers. That they have. Right here, I'm going to publish a crash course on on line launching very soon so that you can see what this I mean, how this actually works, but what I mean is that you have many many language models that you can work with. OK, but since we're going to be working with open AI, we're going to just copy. This right here and we're going to paste it in here. There we go. This one, since it's just our importing which is going to put it right here like that. Now we have, as you can see, it comes in the line chain chains and question answering module. And here we're going to say that this is our language model, which we're going to be using, and our language model is actually going to be open. Like that, OK. And also we're going to have to download it from launching. And also I mean of course this is a open AI language model, but it comes as a wrapper inside of languaging. OK, this doesn't mean it's it comes from launching. It's just a wrapper. So from launching LLNS, I'm going to import open AI. And there we go. Now, right here we have our LLM. We're passing it right here, the. Chain type stuff. That's right. And then we can actually run saying that the input documents are going to be the documents that we just retrieved from, from our knowledge base. And the question that we're going to ask is the user question. There you go. There you go. And now this one actually is going to. It's going to. It's going to return our response like this response.
There you go.
UM. And now I suppose that we can just basically St write our response. And there you go. Do you have any other studies right here? I think that's all right. So this should work. So now just just as a reminder, what we're doing here is. We're catching the question from the input. Then we are performing a semantic search in our knowledge base, which is this thing. Right here and the docs are the ones that the are the results from that semantic search, and then we're using the language model to generate our answer and to do that, we're using this line chain rebuild chain. OK, you're saying that we're looking at it on the docs. User question then showing the response. Let's just save and come back here to our application, refresh and then let's take our. Where is the Constitution? Here? It's. Here and now running and bedding and now we can ask questions about it. And it should know the answer to it. So now let's say what is the minimum age for someone to be elected as senator? 30 years, but it seems to know that if I ask something that is completely unrelated to the Constitution, let's say, what is the? The age of Paul Paul McCartney. Not even sure if that's that's written. All right. The questions now related to the. Context. There you. Go. All right, so that's already an application that's working pretty good. The thing now is that we want to know how much we're spending per question. OK, I'm just going to modularize this pretty quick and then let's cheque. How much money we're spending here. Quick question, let's do that. All right, you know what? I changed my mind. I'm not going to show you how to how I modularized this. I suppose you can do that on yourselves. I'm just going to go directly into the pricing, OK? And how to monitor how much you're spending per question in order to do that. Actually, launching comes with a very convenient monitor. However, it currently only works with open AI, but it allows you to see exactly how much money you spend per operation. In this case, per question answered by the language model. OK, so here what I'm going to do is I'm going to import from line chain. That callbacks. There you go. I'm going to import. Get opening. I call back. OK. And just to show you real quick also here. If you go back to open AI and you come to your platform, that open AI and you see the usage. You will see how much money you have spent per day using their APIs. OK, here in this example and as I'm recording this the same day that I'm uploading it, I've spent 90 cent. Which is quite an expensive budget, just for a few tests and also I mean, keep in mind that this is way more than what you have seen me do. I have been playing around with. It all day so. This is definitely this doesn't account only for the test that you've seen me. Doing the video. So what we're going to do now is we're going to take. This function from Lang chain. And we're going to wrap whenever we are using the open AIS language models. OK. So I'm going to say with this one right here. As callback it's going to say CB it's callback and then inside of it I'm going to run whichever whatever I want to be tracked with. Whatever I want to track the price of. OK, so here I'm going to track how much I'm spending for this generation for executing this chain and then inside of it, I'm just going. To print the callback and that's all actually. Now if I save this. I'm going to I'm going to restart. Stream lit like this. There you go. If I go back to my application. Huh. There you go. I refresh. Actually, I'm going to show you this in real time. Let's see. Here you have the terminal and here you have the the the application is going to put myself. We're going to put myself here and then we're going to take the Constitution again and upload it. There you go. And now we can actually ask whichever question we want. I'm going to ask how many senators does each state have? OK, if I click enter we should see exactly how much money we're spending right here. OK, so let me. Just zoom a. Little bit. Here we go. So you have that the answer is 2. Managers and that operation apparently costed. Around 1000 tokens and it costed me around $0.02 just for one answer. OK which looks pretty good. And then if I ask another question I will get the same thing again like for example. Let's say how? Has the power of the veto legislation. Passed by Congress. Let's saying the president has the power to veto legislation and also around two cents, right? So this is a very convenient function in order to to track your spending. Yeah, I mean, don't forget to use it. You can probably wrap the entire programme in it or entire functions in it. So there you go. That's how to track spending. Right, so now you have your application that's working correctly and you know how much exactly how much you're spending per question. And and we've built it with a graphical user interface, all of it using Python, and I hope that you understand the diet. I mean, what's actually going on behind the scenes in this application? I hope it was clear. Don't forget to ask me if you have any questions. Don't forget to subscribe if you want more videos. Like this and yeah, thank you very much for watching and I'll see you again next time.
